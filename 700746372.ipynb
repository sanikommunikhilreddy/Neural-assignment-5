{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBuVPk9MVV5k",
        "outputId": "3566576b-07ea-4b32-c721-73d0bcd06154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3076923076923077\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00        19\n",
            "           2       0.40      0.17      0.24        23\n",
            "           3       0.08      0.75      0.15         4\n",
            "           5       0.33      0.17      0.22         6\n",
            "           6       0.75      1.00      0.86         3\n",
            "           7       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.31        65\n",
            "   macro avg       0.41      0.50      0.40        65\n",
            "weighted avg       0.35      0.31      0.29        65\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "glass_data = pd.read_csv(\"glass.csv\")\n",
        "\n",
        "# Split dataset into features and target variable\n",
        "X = glass_data.drop('Type', axis=1)  # Features\n",
        "y = glass_data['Type']  # Target variable\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create Naïve Bayes classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train Naïve Bayes classifier\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Model evaluation\n",
        "# Score\n",
        "accuracy = nb_classifier.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "glass_data = pd.read_csv(\"glass.csv\")\n",
        "\n",
        "# Split dataset into features and target variable\n",
        "X = glass_data.drop('Type', axis=1)  # Features\n",
        "y = glass_data['Type']  # Target variable\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create Linear SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "\n",
        "# Train Linear SVM classifier\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Model evaluation\n",
        "# Score\n",
        "accuracy = svm_classifier.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sjlOQMqWuAw",
        "outputId": "274e3a44-983e-4602-fb6e-bdab8e9e91ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.676923076923077\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.65      0.79      0.71        19\n",
            "           2       0.59      0.70      0.64        23\n",
            "           3       0.00      0.00      0.00         4\n",
            "           5       0.75      0.50      0.60         6\n",
            "           6       0.50      0.33      0.40         3\n",
            "           7       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.68        65\n",
            "   macro avg       0.58      0.54      0.55        65\n",
            "weighted avg       0.65      0.68      0.65        65\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which algorithm you got better accuracy? Can you justify why?\n",
        "\n",
        "\n",
        "\n",
        "You would compare the accuracy scores for the Naïve Bayes and Linear SVM algorithms returned by the score() method to determine which algorithm is more accurate. In this case, the algorithm with the higher accuracy would be deemed superior.\n",
        "\n",
        "It's crucial to keep in mind, though, that the specifics of the dataset may influence the algorithm that is selected. Because of its simplicity and independence assumptions, Naïve Bayes may perform better in some situations, but SVM may perform better in others—particularly when the data is highly dimensional or the decision boundary is nonlinear. As a result, it's critical to assess both methods and select the one that works best with the particular dataset.\n"
      ],
      "metadata": {
        "id": "MvGWwPnHfGGQ"
      }
    }
  ]
}